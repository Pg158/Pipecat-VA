# ğŸ™ï¸ Pipecat Voice Assistant

[![Streamlit App](https://img.shields.io/badge/Launch%20App-Streamlit-informational?style=for-the-badge&logo=streamlit)](https://pipecat-va-hakljyonk4mmbaddqsru4t.streamlit.app/)

**Pipecat Voice Assistant** is a modular voice interaction system built using [Pipecat](https://github.com/anysphere/pipecat), an open-source pipelining framework for AI applications. This app demonstrates how you can build a flexible and powerful speech-based assistant in Python by combining:

- ğŸ¤ Speech-to-Text (STT) via Deepgram
- ğŸ§  Large Language Model (LLM) via Gemini (or GPT/Claude)
- ğŸ”Š Text-to-Speech (TTS) via Kokoro
- ğŸ§© A plug-and-play modular pipeline architecture using Pipecat

The app runs entirely in your browser thanks to **Streamlit Cloud**, making it ideal for demos, learning projects, or production prototypes.

---

## âœ¨ Features

- **ğŸ™ï¸ Record Voice** from browser using `st.audio_input`
- **ğŸ“ƒ Speech-to-Text** using Deepgram API
- **ğŸ¤– LLM response generation** using Gemini or any custom LLM
- **ğŸ—£ï¸ Text-to-Speech** using Kokoroâ€™s expressive voice models
- **ğŸ” Modular Pipeline** using Pipecat processors (`FrameProcessor`, `ConsumerProcessor`)
- **ğŸš€ Deployed on Streamlit Cloud** â€“ no frontend coding needed
- **ğŸ§© Extensible and Swappable** â€“ plug in your own STT, LLM, or TTS

---

## ğŸ§  Pipecat Pipeline Architecture

At its core, this app uses **Pipecatâ€™s processor-based pipeline system** to create a fully asynchronous flow of data. The voice assistant is structured like this:

```text
[ ğŸ™ï¸ Mic Input ]
      â†“
[ MicInputProducer ]        # Takes Streamlit audio input and wraps it in AudioRawFrame
      â†“
[ STTProcessor ]            # Transcribes speech using Deepgram
      â†“
[ LLMProcessor ]            # Generates response using Gemini/GPT/Groq(models)
      â†“
[ TTSProcessor ]            # Synthesizes speech using Kokoro TTS
      â†“
[ ğŸ”Š Output to Browser ]
```

## ğŸ› ï¸ Installation (Local)
```
# Clone the repository
git clone https://github.com/Pg158/pipecat-va.git
cd pipecat-va

# Create a virtual environment and activate it
conda create -n pipecat python=3.11
conda activate pipecat

# Install dependencies
pip install -r requirements.txt

# Run the Streamlit app locally
streamlit run app.py
```

## ğŸ§¾ Requirements
Make sure your requirements.txt includes:
```
streamlit
pipecat
numpy
scipy
soundfile
torch
torchaudio
transformers
huggingface-hub
kokoro
deepgram-sdk==4.6.0
python-dotenv
```
#### âš ï¸ Do not include simpleaudio if deploying to Streamlit Cloud â€” it may cause build errors. Audio is played via st.audio() on the web.
---

## ğŸŒ Deployment (Streamlit Cloud)
Push your code to a GitHub repository

Go to Streamlit Cloud

Click "New App"

Choose your repo, branch, and set app.py as the entry point

Click "Deploy" and youâ€™re live!

#### Make sure your API keys (Deepgram, Gemini, etc.) are set via Streamlit's secrets manager or .env file (when running locally).
---

## ğŸ“œ License
MIT License. This project is for educational, demonstration, and personal use.

---

## ğŸ™‹â€â™€ï¸ Acknowledgements

Pipecat by Pipecat-ai

Deepgram Speech-to-Text

Kokoro TTS

Streamlit Cloud